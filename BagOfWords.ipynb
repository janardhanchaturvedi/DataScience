{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931a7572",
   "metadata": {},
   "source": [
    "# import the necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483ac7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37463e8",
   "metadata": {},
   "source": [
    "# User defined dataset ( Two simple documents containing one sentence each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9499fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentA = 'the man went out for a walk '\n",
    "documentB = 'the children sat around the fire'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad5bcc",
   "metadata": {},
   "source": [
    "# BoW(To convert text into vectors of numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce136e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'man', 'went', 'out', 'for', 'a', 'walk', '']\n",
      "['the', 'children', 'sat', 'around', 'the', 'fire']\n"
     ]
    }
   ],
   "source": [
    "#spilts two documents in individuals words\n",
    "bagOfWordsA = documentA.split(' ')\n",
    "bagOfWordsB = documentB.split(' ')\n",
    "\n",
    "print(bagOfWordsA)\n",
    "print(bagOfWordsB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab4adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any duplicate words\n",
    "\n",
    "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79c5248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'fire': 0, 'walk': 0, 'around': 0, 'out': 0, 'a': 0, 'went': 0, 'children': 0, 'for': 0, 'sat': 0, 'the': 0, 'man': 0}\n"
     ]
    }
   ],
   "source": [
    "#Creater a dictnoary of words and their occurence for each documents in the cor\n",
    "\n",
    "numOfWordsA = dict.fromkeys(uniqueWords,0)\n",
    "print(numOfWordsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9f22f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fire  walk  around  out  a  went  children  for  sat  the  man\n",
      "0  1     0     1       0    1  1     1         0    1    0    1    1\n",
      "1  0     1     0       1    0  0     0         1    0    1    2    0\n"
     ]
    }
   ],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords,0)\n",
    "\n",
    "for word in bagOfWordsA:\n",
    "    numOfWordsA[word] += 1\n",
    "    \n",
    "numOfWordsB = dict.fromkeys(uniqueWords,0)\n",
    "\n",
    "for word in bagOfWordsB:\n",
    "    numOfWordsB[word] += 1\n",
    "    \n",
    "df = pd.DataFrame([numOfWordsA,numOfWordsB])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6e18c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('', 0), ('fire', 1), ('walk', 0), ('around', 1), ('out', 0), ('a', 0), ('went', 0), ('children', 1), ('for', 0), ('sat', 1), ('the', 2), ('man', 0)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfWordsB.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a26f8b",
   "metadata": {},
   "source": [
    "# Term Frequency (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "332724e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict , bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word , count in wordDict.items():\n",
    "        tfDict[word]= count/ float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee5810e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0.0,\n",
       " 'fire': 0.16666666666666666,\n",
       " 'walk': 0.0,\n",
       " 'around': 0.16666666666666666,\n",
       " 'out': 0.0,\n",
       " 'a': 0.0,\n",
       " 'went': 0.0,\n",
       " 'children': 0.16666666666666666,\n",
       " 'for': 0.0,\n",
       " 'sat': 0.16666666666666666,\n",
       " 'the': 0.3333333333333333,\n",
       " 'man': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computer the term Frequecy for each of Documents\n",
    "\n",
    "tfA = computeTF(numOfWordsA , bagOfWordsA)\n",
    "tfB = computeTF(numOfWordsB, bagOfWordsB)\n",
    "\n",
    "tfA\n",
    "tfB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e2bc0",
   "metadata": {},
   "source": [
    "# Inverse Data frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60406922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(),0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "                \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N/float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40e4160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0.6931471805599453, 'fire': 0.6931471805599453, 'walk': 0.6931471805599453, 'around': 0.6931471805599453, 'out': 0.6931471805599453, 'a': 0.6931471805599453, 'went': 0.6931471805599453, 'children': 0.6931471805599453, 'for': 0.6931471805599453, 'sat': 0.6931471805599453, 'the': 0.0, 'man': 0.6931471805599453}                  fire      walk    around       out         a      went  \\\n",
      "0  0.693147  0.693147  0.693147  0.693147  0.693147  0.693147  0.693147   \n",
      "\n",
      "   children       for       sat  the       man  \n",
      "0  0.693147  0.693147  0.693147  0.0  0.693147  \n"
     ]
    }
   ],
   "source": [
    "# The  IDF is computed once for all documents\n",
    "\n",
    "idfs = computeIDF([numOfWordsA,numOfWordsB])\n",
    "df = pd.DataFrame([idfs])\n",
    "\n",
    "print(idfs,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "204487d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the TF-IDf is simply the TF multiplied by IDF\n",
    "\n",
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word , val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "        \n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efd7282f",
   "metadata": {},
   "outputs": [],
   "source": [
    " #computer the TF- IDf scores for all the words in the corpus\n",
    "\n",
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "df = pd.DataFrame([tfidfA,tfidfB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1aba74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 fire      walk    around       out         a      went  \\\n",
      "0  0.086643  0.000000  0.086643  0.000000  0.086643  0.086643  0.086643   \n",
      "1  0.000000  0.115525  0.000000  0.115525  0.000000  0.000000  0.000000   \n",
      "\n",
      "   children       for       sat  the       man  \n",
      "0  0.000000  0.086643  0.000000  0.0  0.086643  \n",
      "1  0.115525  0.000000  0.115525  0.0  0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a4dd950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b963b919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "Building wheels for collected packages: Afinn\n",
      "  Building wheel for Afinn (setup.py): started\n",
      "  Building wheel for Afinn (setup.py): finished with status 'done'\n",
      "  Created wheel for Afinn: filename=afinn-0.1-py3-none-any.whl size=53447 sha256=626507056adc99f652072f23a6cb921cbbd87b6d1ffe98ec41a80c6e0c97971f\n",
      "  Stored in directory: c:\\users\\sap\\appdata\\local\\pip\\cache\\wheels\\79\\91\\ee\\8374d9bc8c6c0896a2db75afdfd63d43653902407a0e76cd94\n",
      "Successfully built Afinn\n",
      "Installing collected packages: Afinn\n",
      "Successfully installed Afinn-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eda6ec8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af = Afinn()\n",
    "af.score(\"This movie is very long and scary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d1eb1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\sap\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\sap\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sap\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sap\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\sap\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sap\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e460d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6fdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
